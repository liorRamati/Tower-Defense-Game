{
    "name": "root",
    "gauges": {
        "BasicSAC.Policy.Entropy.mean": {
            "value": 1.8838592767715454,
            "min": 1.8838592767715454,
            "max": 2.0652284622192383,
            "count": 83
        },
        "BasicSAC.Policy.Entropy.sum": {
            "value": 9440.0185546875,
            "min": 9423.029296875,
            "max": 10336.46875,
            "count": 83
        },
        "BasicSAC.Step.mean": {
            "value": 414978.0,
            "min": 4941.0,
            "max": 414978.0,
            "count": 83
        },
        "BasicSAC.Step.sum": {
            "value": 414978.0,
            "min": 4941.0,
            "max": 414978.0,
            "count": 83
        },
        "BasicSAC.Policy.ExtrinsicValue.mean": {
            "value": -48.49419021606445,
            "min": -53.77775192260742,
            "max": -0.37133923172950745,
            "count": 83
        },
        "BasicSAC.Policy.ExtrinsicValue.sum": {
            "value": -3928.029541015625,
            "min": -4302.22021484375,
            "max": -29.335798263549805,
            "count": 83
        },
        "BasicSAC.Environment.EpisodeLength.mean": {
            "value": 866.1666666666666,
            "min": 745.0,
            "max": 1212.25,
            "count": 83
        },
        "BasicSAC.Environment.EpisodeLength.sum": {
            "value": 5197.0,
            "min": 3832.0,
            "max": 5948.0,
            "count": 83
        },
        "BasicSAC.Environment.CumulativeReward.mean": {
            "value": -0.9229582071614763,
            "min": -1.2586999471920233,
            "max": 1.7851801253855228,
            "count": 83
        },
        "BasicSAC.Environment.CumulativeReward.sum": {
            "value": -5.537749242968857,
            "min": -7.552199683152139,
            "max": 8.925900626927614,
            "count": 83
        },
        "BasicSAC.Policy.ExtrinsicReward.mean": {
            "value": -0.9229582071614763,
            "min": -1.2586999471920233,
            "max": 1.7851801253855228,
            "count": 83
        },
        "BasicSAC.Policy.ExtrinsicReward.sum": {
            "value": -5.537749242968857,
            "min": -7.552199683152139,
            "max": 8.925900626927614,
            "count": 83
        },
        "BasicSAC.Losses.PolicyLoss.mean": {
            "value": 98.495296971887,
            "min": -0.6109516693708227,
            "max": 103.73979145308303,
            "count": 83
        },
        "BasicSAC.Losses.PolicyLoss.sum": {
            "value": 49346.14378291539,
            "min": -240.71495773210412,
            "max": 51662.416143635346,
            "count": 83
        },
        "BasicSAC.Losses.ValueLoss.mean": {
            "value": 0.017068548267698377,
            "min": 0.0036264451951744984,
            "max": 0.022198266000970315,
            "count": 83
        },
        "BasicSAC.Losses.ValueLoss.sum": {
            "value": 8.551342682116887,
            "min": 1.8059697071969,
            "max": 11.099133000485157,
            "count": 83
        },
        "BasicSAC.Losses.Q1Loss.mean": {
            "value": 0.41631535745945786,
            "min": 0.0003410782862873281,
            "max": 0.6892053600315847,
            "count": 83
        },
        "BasicSAC.Losses.Q1Loss.sum": {
            "value": 208.5739940871884,
            "min": 0.17053914314366403,
            "max": 342.5350639356976,
            "count": 83
        },
        "BasicSAC.Losses.Q2Loss.mean": {
            "value": 0.42688996424149983,
            "min": 0.0003291749562236353,
            "max": 0.711260123974843,
            "count": 83
        },
        "BasicSAC.Losses.Q2Loss.sum": {
            "value": 213.87187208499142,
            "min": 0.16458747811181768,
            "max": 353.49628161549697,
            "count": 83
        },
        "BasicSAC.Policy.DiscreteEntropyCoeff.mean": {
            "value": 0.4651125357995389,
            "min": 0.4651125357995389,
            "max": 0.4997078358073481,
            "count": 83
        },
        "BasicSAC.Policy.DiscreteEntropyCoeff.sum": {
            "value": 233.02138043556897,
            "min": 196.88488730809516,
            "max": 250.1518365978485,
            "count": 83
        },
        "BasicSAC.Policy.ContinuousEntropyCoeff.mean": {
            "value": 0.46508812720249754,
            "min": 0.46508812720249754,
            "max": 0.4997078358073481,
            "count": 83
        },
        "BasicSAC.Policy.ContinuousEntropyCoeff.sum": {
            "value": 233.00915172845126,
            "min": 196.88488730809516,
            "max": 250.15094157535407,
            "count": 83
        },
        "BasicSAC.Policy.LearningRate.mean": {
            "value": 5.250713147441118e-07,
            "min": 5.250713147441118e-07,
            "max": 2.9819601546477156e-06,
            "count": 83
        },
        "BasicSAC.Policy.LearningRate.sum": {
            "value": 0.0002630607286868,
            "min": 0.0002630607286868,
            "max": 0.0014775702396835999,
            "count": 83
        },
        "BasicSAC.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 83
        },
        "BasicSAC.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 83
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1646666476",
        "python_version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\liorr\\Documents\\UnityProjects\\cats tower defense\\venv\\Scripts\\mlagents-learn config/BasicSAC.yaml --run-id=TestSACLevel2 --time-scale=10 --force",
        "mlagents_version": "0.28.0",
        "mlagents_envs_version": "0.28.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.5",
        "end_time_seconds": "1646675713"
    },
    "total": 9236.340998099999,
    "count": 1,
    "self": 0.004701799998656497,
    "children": {
        "run_training.setup": {
            "total": 0.07743129999999998,
            "count": 1,
            "self": 0.07743129999999998
        },
        "TrainerController.start_learning": {
            "total": 9236.258865,
            "count": 1,
            "self": 6.806390400246528,
            "children": {
                "TrainerController._reset_env": {
                    "total": 7.825367299999999,
                    "count": 1,
                    "self": 7.825367299999999
                },
                "TrainerController.advance": {
                    "total": 9220.937882299755,
                    "count": 419543,
                    "self": 7.5269981999972515,
                    "children": {
                        "env_step": {
                            "total": 6979.906745399842,
                            "count": 419543,
                            "self": 5241.538266999462,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1733.6566151002626,
                                    "count": 419543,
                                    "self": 21.276815600597956,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1712.3797994996646,
                                            "count": 419091,
                                            "self": 391.6341197994923,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 1320.7456797001723,
                                                    "count": 419091,
                                                    "self": 1320.7456797001723
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 4.711863300116994,
                                    "count": 419542,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 9217.216597100383,
                                            "count": 419542,
                                            "is_parallel": true,
                                            "self": 4311.111121200177,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00040160000000000196,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0001930000000003318,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00020859999999967016,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.00020859999999967016
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 4906.105074300206,
                                                    "count": 419542,
                                                    "is_parallel": true,
                                                    "self": 33.17554359973201,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 25.991145500125565,
                                                            "count": 419542,
                                                            "is_parallel": true,
                                                            "self": 25.991145500125565
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 4719.816058400245,
                                                            "count": 419542,
                                                            "is_parallel": true,
                                                            "self": 4719.816058400245
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 127.12232680010284,
                                                            "count": 419542,
                                                            "is_parallel": true,
                                                            "self": 67.91000210090597,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 59.21232469919687,
                                                                    "count": 1678168,
                                                                    "is_parallel": true,
                                                                    "self": 59.21232469919687
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 2233.504138699916,
                            "count": 419542,
                            "self": 11.420255300381086,
                            "children": {
                                "process_trajectory": {
                                    "total": 56.54393029943513,
                                    "count": 419542,
                                    "self": 56.54393029943513
                                },
                                "_update_policy": {
                                    "total": 2165.5399531001,
                                    "count": 418527,
                                    "self": 2.395163600039268,
                                    "children": {
                                        "SACTrainer._update_policy": {
                                            "total": 2163.1447895000606,
                                            "count": 418527,
                                            "self": 171.08362379988785,
                                            "children": {
                                                "TorchSACOptimizer.update": {
                                                    "total": 1992.0611657001728,
                                                    "count": 41808,
                                                    "self": 1992.0611657001728
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.7999991541728377e-06,
                    "count": 1,
                    "self": 1.7999991541728377e-06
                },
                "TrainerController._save_models": {
                    "total": 0.6892231999991054,
                    "count": 1,
                    "self": 0.12252799999987474,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.5666951999992307,
                            "count": 1,
                            "self": 0.5666951999992307
                        }
                    }
                }
            }
        }
    }
}